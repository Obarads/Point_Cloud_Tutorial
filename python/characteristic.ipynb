{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Characteristic\n",
    "A point cloud is a set of points with coordinates, and different from an image and meshes. In this section, we introduce the following characteristics of the point cloud. \n",
    "- Properties of points\n",
    "- Point density\n",
    "- Definition of Neighborhood\n",
    "- Invariance to a rigid transformation\n",
    "- unordered points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Properties of points\n",
    "Points have coordinats and the coordinates are XYZ values. Points have coordinates, and the coordinates are XYZ values. The point position depends on the coordinates.\n",
    "\n",
    "Also, points can have colors and normals, etc.\n",
    "- **Color (RGB)**: the color is used when displaying points on viewers, or for point cloud processing.\n",
    "- **Normals**: we can get the surface of a 3D object or detect planes from normals.\n",
    "- **Intensity**:  \"intensity\" is the laser reflection intensity, and depends on the reflectivity of the object surface that the laser hits. Intensity can be used for feature extraction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point density\n",
    "There are density differences of points in a point cloud because points are not arranged regularly. An example of a point density difference is a point distribution acquired from a sensor. You can confirm a point cloud acquired from a sensor by following code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "955e921fa04848d9bb76774f13ba365e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tutlibs.io import Points\n",
    "from tutlibs.visualization import JupyterVisualizer as jv\n",
    "coords, colors, _ = Points.read(\"../data/kitti_sample.ply\")\n",
    "obj_points = jv.point(coords, colors, point_size=0.07)\n",
    "jv.display([obj_points])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The point colors in outputs show the distance from the sensor to the point, and red is the closest. Let's compare the surrounding of the orange and blue points. You can see that the orange point has a dense point around it, while the blue point is sparse. The density differences of points affect point cloud processing such as nearest neighbor search, downsampling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of Neighborhood\n",
    "Point clouds do not have clearly defined adjacencies between points.\n",
    "Characteristics that lack clear adjacency relationships can create problems. For example, it prevents the application of convolution algorithms that require adjacent elements. These problems can be solved in the following ways\n",
    "\n",
    "1. perform a k-nearest neighbor (kNN), ball query, etc. on each point in the point cloud to make the points have adjacencies to nearby points.\n",
    "2. convert the point cloud to a voxel representation.\n",
    "\n",
    "The first method is often used to collect information around a point. For example, when generating a handcrafted feature, kNN is used to reference information about other points around a point. In addition, in processes with convolution mechanisms, such as deep learning methods, kNN is used to convolve the features of surrounding points as well.\n",
    "The second method allows the point cloud to be converted into a data format along a grid, such as an image. This allows, for example, the application of a 3D CNN in deep learning, which is an extension of the 2D CNN for images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invariance to rigid transformations (by task)\n",
    "Rigid body transformations can be used to change the orientation or translate a point cloud without destroying the shape of the point cloud. Depending on the task, it is necessary to ensure that the result of processing a rigid-body transformed point cloud does not change. For example, in an object classification task, the input point cloud may not have a constant orientation, and if it does, it is necessary to make predictions that are invariant to any orientation.\n",
    "The phrase \"depending on the task\" is used because tasks that predict the posture or position itself (e.g., posture estimation) are not applicable. These tasks must make predictions according to the attitude and position of the given data.\n",
    "\n",
    "<!-- ## 剛体変換に対する不変性 (タスクによる)\n",
    "点群に対して剛体変換を用いることで点群が持つ形状を崩さずに姿勢の変更や平行移動が可能です。タスクによっては剛体変換された点群に対する処理結果が変化しないようにする必要があります。例えばオブジェクトに対する分類タスクでは、与えられる入力点群の姿勢が一定ではない可能性があり、一定でない場合はどの様な姿勢に対しても不変な予測を行う必要があります。\n",
    "「タスクによる」とあるのは、姿勢や位置そのものを予測するタスク(例:姿勢推定)などが当てはまらないためです。これらのタスクは、与えられたデータの姿勢や位置に合わせて予測を行う必要があります。\n",
    " -->\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 点の順不同による形状不変性\n",
    "\n",
    "点群は画像や文字列の様に要素に順序があるわけではないため、点の入力順序を変更したとしても点群が示す形状は変わりません。例えば、オブジェクト点群内にある点の順序をランダムに入れ替えたとしても、オブジェクトの形状は変わりません。\n",
    "例として、オリジナルの点群と点の順序を入れ替えた点群をそれぞれ表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "点の順序入れ替え前と後を表示するコードは以下のとおりです。X軸で0~1の間にあるウサギの点群が入れ替え前、1~2の間にあるウサギの点群が入れ替え後です。  \n",
    "Note: 見比べを行うために入れ替え後の点群の位置を平行移動させています。  \n",
    "問題点: 平行移動による形状が変わらないことへの言及がない\n",
    "\n",
    "上の出力から見てわかるように、ウサギの形状も色も変わってないことが示されていると思います。  \n",
    "実際にこれらの点群を処理する場合、その手法の出力は点群の点の順序に依存しない処理方法が必要となります。例えば機械学習の分野の分類タスクを解く場合、ある点群AとAの点の順序を変えた点群Bを機械学習モデルに入力したとしても、AとBの分類予測ラベルは同じでなければいけません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "interpreter": {
   "hash": "4b28c7e065dc872b238847722c3716b3aa1fa0ead1eaaaca0154caa64a92cae9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('pct_cpu': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
