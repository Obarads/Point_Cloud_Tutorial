{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handcrafted Feature\n",
    "In this section, we introduce handcrafted features for a point cloud data. The handcrafted feature is data encoded of shape property and can be extracted on a point-by-point from raw data such as coordinates or colors. A common use case with the handcrafted feature is the registration task. An example of a registration pipeline using Handcrafted fetature is shown below. Registration is the relative coordinate estimation task between 2 point clouds and uses the handcrafted features to find correspondence points between 2 point clouds:\n",
    "1. Pre-processing select the point to apply the handcrafted feature and then estimate normals for selected points.\n",
    "2. Feature extraction computes handcrafted features of the points from normal and coordinates.\n",
    "3. Post-processing estimates transformation matrix between two point clouds with correspondences between points based on distances in the feature space.\n",
    "\n",
    "![processing](img/registration_with_handcrafted_feature.png)\n",
    "\n",
    "Section 4 of [Rusu, 2010] explain background of handcrafted features: \n",
    "\n",
    "> In their native representation, points as defined in the concept of 3D mapping systems are simply represented using their Cartesian coordinates $x, y, z$, with respect to a given origin. Assuming that the origin of the coordinate system does not change over time, there could be two points $p_1$ and $p_2$ , acquired at $t_1$ and $t_2$ , having the same coordinates. Comparing these points however is an ill-posed problem, because even though they are equal with respect to some distance measure (e.g. Euclidean metric), they could be sampled on completely different surfaces, and thus represent totally different information when taken together with the other surrounding points in their vicinity. That is because there are no guarantees that the world has not changed between $t_1$ and $t_2$. Some acquisition devices might provide extra information for a sampled point, such as an intensity or surface remission value, or even a color, however that does not solve the problem completely and the comparison remains ambiguous.\n",
    "\n",
    "> Applications which need to compare points for various reasons require better characteristics and metrics to be able to distinguish between geometric surfaces. The concept of a 3D point as a singular entity with Cartesian coordinates therefore disappears, and a new concept, that of local descriptor takes its place. The literature is abundant of different naming schemes describing the same conceptualization, such as shape descriptors or geometric features but for the remaining of this document they will be referred to as point feature representations.\n",
    "\n",
    "In this section, we introduce a usage example and methods of the handcrafted feature.\n",
    "- Registration task solution with the handcrafted feature\n",
    "- PFH (Point Feature Histograms)\n",
    "- FPFH (Fast Point Feature Histograms)\n",
    "- PPF (Point Pair Feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registration task solution with the handcrafted feature\n",
    "This subsection will demonstrate an usage example of the Point Feature Histogram (PFH) with registration task. PFH is a handcrafted feature that supplies a histogram between relationships of neighbor features.\n",
    "\n",
    "An example of Registration is shown below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "# for registration\n",
    "from tutlibs.sampling import voxel_grid_sampling\n",
    "from tutlibs.registration import feature_ransac\n",
    "from tutlibs.feature import PointFeatureHistograms as pfh\n",
    "from tutlibs.normal_estimation import normal_estimation, normal_orientation\n",
    "\n",
    "# for description\n",
    "import numpy as np\n",
    "from tutlibs.transformation import TransformationMatrix as tm\n",
    "from tutlibs.transformation import Transformation as tr\n",
    "from tutlibs.io import Points as io\n",
    "from tutlibs.visualization import JupyterVisualizer as jv\n",
    "from tutlibs.utils import single_color\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed2de64861db4346921d1b5a0e13dc43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# processing for target point cloud\n",
    "target_xyz, _, _ = io.read(\"../data/redwood_indoor_1.ply\")\n",
    "target_ds_xyz = voxel_grid_sampling(target_xyz, 0.05)\n",
    "target_ds_normal = normal_estimation(target_ds_xyz, k=15)\n",
    "target_ds_normal = normal_orientation(target_ds_xyz, target_ds_normal)\n",
    "\n",
    "# processing for source point cloud\n",
    "source_xyz, _, _ = io.read(\"../data/redwood_indoor_2.ply\")\n",
    "source_xyz = tr.rotation(source_xyz, \"y\", np.pi / 3)\n",
    "source_ds_xyz = voxel_grid_sampling(source_xyz, 0.05)\n",
    "source_ds_normal = normal_estimation(source_ds_xyz, k=15)\n",
    "source_ds_normal = normal_orientation(source_ds_xyz, source_ds_normal)\n",
    "\n",
    "# extract Handcrafted feature\n",
    "source_ds_pfh = pfh.compute(source_ds_xyz, source_ds_normal, 0.25)\n",
    "target_ds_pfh = pfh.compute(target_ds_xyz, target_ds_normal, 0.25)\n",
    "\n",
    "# feature matching\n",
    "trans_mat = feature_ransac(\n",
    "    source_ds_xyz, target_ds_xyz, source_ds_pfh, target_ds_pfh, 3, 10000, 0.05\n",
    ")\n",
    "trans_source_xyz = tm.transformation(source_ds_xyz, trans_mat)\n",
    "\n",
    "# visualize results\n",
    "obj_source_points = jv.point(\n",
    "    source_ds_xyz, single_color(\"#ff0000`\", len(source_ds_xyz))\n",
    ")\n",
    "obj_trans_source_points = jv.point(\n",
    "    trans_source_xyz, single_color(\"#00ff00\", len(trans_source_xyz))\n",
    ")\n",
    "obj_target_points = jv.point(target_ds_xyz, single_color(\"#ffff00\", len(target_ds_xyz)))\n",
    "jv.display([obj_trans_source_points, obj_target_points, obj_source_points])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above implementation, we estimate the position of source points relative to target points. The red point cloud is the initial position of source points, yellow is the transformed source point cloud, and green is the target point cloud.\n",
    "The method with PFH is more robust than the simple method (ex: ICP) since PFH includes relative angle features between normals that do not depend on object position and direction.\n",
    "Because this output shows that the source point cloud nearly overlaps with the target point cloud, PFH features are good in this registration example.\n",
    "\n",
    "There are handcrafted features other than PFH. In the next subsection, we introduce handcrafted features and its detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PFH (Point Feature Histograms)\n",
    "PFH [Rusu et al, 2008] is a histogram feature of relative angles and distances between neighbor points.\n",
    "\n",
    "This subsection use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from tutlibs.normal_estimation import normal_estimation\n",
    "from tutlibs.feature import PointFeatureHistograms as pfh\n",
    "from tutlibs.feature import pair_feature\n",
    "\n",
    "from tutlibs.io import Points as io\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PFH shape: (4093, 125)\n"
     ]
    }
   ],
   "source": [
    "xyz, _, _ = io.read('../data/bunny_pc.ply')\n",
    "normals = normal_estimation(xyz, 15)\n",
    "pfhs = pfh.compute(xyz, normals)\n",
    "print('PFH shape: {}'.format(pfhs.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pfh.compute` outputs a 125 bin histogram by point from coordinates and a normal.\n",
    "The following output shows a content of `pfh.compute`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    @staticmethod\n",
      "    def compute(\n",
      "        xyz: np.ndarray,\n",
      "        normals: np.ndarray,\n",
      "        radius=0.03,\n",
      "        div: int = 5,\n",
      "        normalization: bool = True,\n",
      "    ) -> np.ndarray:\n",
      "        \"\"\"Compute Point Feature Histograms.\n",
      "        Note: does not include the distance feature (reason -> https://pcl.readthedocs.io/projects/tutorials/en/latest/pfh_estimation.html#pfh-estimation)\n",
      "\n",
      "        Args:\n",
      "            xyz: xyz coords (N, 3)\n",
      "            normals: normals (N, 3)\n",
      "            radius: radius for nearest neighbor search\n",
      "            div: number of subdivisions of value range for each feature.\n",
      "            normalization: normalize each point histgram.\n",
      "\n",
      "        Return:\n",
      "            point feature histograms: (N, div**3)\n",
      "        \"\"\"\n",
      "        knn_idxs, _ = radius_nearest_neighbors(xyz, xyz, r=radius)\n",
      "\n",
      "        # define PFH list\n",
      "        num_pf = len(knn_idxs)  # num_pf = N = xyz.shape[0]\n",
      "        pfh_list = np.zeros((num_pf, div ** 3))\n",
      "\n",
      "        for i in range(num_pf):\n",
      "            # Get point set in radius (R=number of points in radius, R is different for each i.)\n",
      "            rnn_xyz = xyz[knn_idxs[i]]  # shape: (R, 3)\n",
      "            rnn_normal = normals[knn_idxs[i]]  # shape: (R, 3)\n",
      "\n",
      "            if len(rnn_xyz) >= 2:\n",
      "                pair_idxs = np.array(\n",
      "                    list(itertools.combinations(range(len(rnn_xyz)), 2))\n",
      "                )  # shape: (T, 2), T=Number of combinations\n",
      "                phi, alpha, theta, _ = pair_feature(\n",
      "                    rnn_xyz, rnn_normal, pair_idxs\n",
      "                )  # shape: (T), (T), (T), (T)\n",
      "\n",
      "                theta_bin_idx = fminmax(\n",
      "                    np.floor((div * (theta + np.pi)) / (2.0 * np.pi)), 0, div - 1\n",
      "                )\n",
      "                alpha_bin_idx = fminmax(\n",
      "                    np.floor(div * ((alpha + 1.0) * 0.5)), 0, div - 1\n",
      "                )\n",
      "                phi_bin_idx = fminmax(np.floor(div * ((phi + 1.0) * 0.5)), 0, div - 1)\n",
      "\n",
      "                histgram_idx = (\n",
      "                    phi_bin_idx * (div ** 2) + alpha_bin_idx * (div) + theta_bin_idx\n",
      "                ).astype(np.int32)\n",
      "                histgram = np.bincount(histgram_idx, minlength=div ** 3).astype(\n",
      "                    np.float32\n",
      "                )\n",
      "                if normalization:\n",
      "                    histgram /= (\n",
      "                        len(rnn_xyz) * (len(rnn_xyz) - 1) / 2\n",
      "                    )  # ex: np.sum(histgram) = 1\n",
      "            else:\n",
      "                histgram = np.zeros(div ** 3)\n",
      "\n",
      "            pfh_list[i] = histgram\n",
      "\n",
      "        return pfh_list\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(pfh.compute))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In above implementation, \n",
    "\n",
    "1. get neighbors for each point by `radius_nearest_neighbors` function. In the figure below, we use an any point as the query point (red point) and neighbors (blue points) within a fixed distance (inside the dotted line) from the query point.\n",
    "2. calculate PFH for each point. To calculate the PFH of a point, we use the query point and the neighbor points obtained on 1.\n",
    "   1. create all combinations of two points with the query point and its neighbors. The figure shows two point combinations as edges.\n",
    "   2. use the `pair_feature` function to obtain the feature between points for each combination.\n",
    "   3. obtain PFH that split the features to bins of histogram.\n",
    "\n",
    "![nn](img/pfh_nn.png)  \n",
    "[by Rusu et al, 2009]\n",
    "\n",
    "Next, we show `pair_feature` to compute feature between points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def pair_feature(xyz:np.ndarray, normals:np.ndarray, pair_idxs:np.ndarray):\n",
      "    \"\"\"Compute pair features.\n",
      "\n",
      "    Args:\n",
      "        xyz: xyz coords (M, 3)\n",
      "        normals: normals (M, 3)\n",
      "        pair_idxs: point pair indices (L, 2)\n",
      "    Return:\n",
      "        phi: cosine feature, value range is -1~1 (L)\n",
      "        alpha: cosine feature, value range is -1~1 (L)\n",
      "        theta: angle feature, value range is -pi/2~pi/2 (L)\n",
      "        dists: distance feature (L)\n",
      "    \"\"\"\n",
      "    # Get xyz and normal of points\n",
      "    p1 = xyz[pair_idxs[:, 0]]\n",
      "    n1 = normals[pair_idxs[:, 0]]\n",
      "    p2 = xyz[pair_idxs[:, 1]]\n",
      "    n2 = normals[pair_idxs[:, 1]]\n",
      "\n",
      "    # Get vectors (pp) and distances (dists) between pt and ps\n",
      "    pp = p2 - p1\n",
      "    dists = np.linalg.norm(pp, ord=2, axis=1)\n",
      "\n",
      "    # Get a mask to decide the source and target points.\n",
      "    p1pp_angle = dot(n1, pp) / dists\n",
      "    p2pp_angle = dot(n2, pp) / dists\n",
      "    mask = np.arccos(np.fabs(p1pp_angle)) > np.arccos(np.fabs(p2pp_angle))\n",
      "\n",
      "    # Decide source and target points.\n",
      "    phi = p1pp_angle.copy()\n",
      "    u = n1.copy() # u = ns\n",
      "    nt = n2.copy()\n",
      "    u[mask] = n2[mask].copy()\n",
      "    nt[mask] = n1[mask].copy()\n",
      "    pp[mask] *= -1\n",
      "    phi[mask] = -1 * p2pp_angle[mask]\n",
      "\n",
      "    # Compute v and w\n",
      "    v = normalize(cross(pp, u))\n",
      "    w = cross(u, v)\n",
      "\n",
      "    # Get alpha and theta\n",
      "    alpha = dot(v, nt)\n",
      "    theta = np.arctan2(dot(w, nt), dot(u, nt))\n",
      "\n",
      "    return phi, alpha, theta, dists\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(pair_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In above implementation, we input coordinates, normals and $L$ pair indices to `pair_feature` and then `pair_feature` outputs features of each pair (pair feature). Pair features are 3 relative angle between normals and relative postion ($\\phi$, $\\alpha$ and $\\theta$) and one relative distance ($d$). Note that the implementation does not use $d$ when compute PFH.\n",
    "\n",
    "Let the two points be $P_S$ and $P_T$, respectively. $P_S$ have the smaller angle between the self normal and the relative direction of two points than $P_T$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\text{if } \\left\\langle n_{i}, p_{j}-p_{i}\\right\\rangle \\leq\\left\\langle n_{j}, p_{i}-p_{j}\\right\\rangle \\\\\n",
    "&\\text{then } p_{s}=p_{i}, p_{t}=p_{j} \\\\\n",
    "&\\text{else } p_{s}=p_{j}, p_{t}=p_{i}  \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The pair features are then as follows.\n",
    "\n",
    "![pf](img/pfh_pf.png)  \n",
    "[by Rusu et al, 2010]\n",
    "\n",
    "$$\n",
    "\n",
    "\\begin{aligned}\n",
    "&\\alpha =\\left\\langle v, n_{t}\\right\\rangle \\\\\n",
    "&d =\\left\\|p_{t}-p_{s}\\right\\| \\\\\n",
    "&\\phi =\\left\\langle u, p_{t}-p_{s}\\right\\rangle / f_{2} \\\\\n",
    "&\\theta=\\operatorname{atan}\\left(\\left\\langle w, n_{t}\\right\\rangle,\\left\\langle u, n_{t}\\right\\rangle\\right)\n",
    "\\end{aligned}\n",
    "\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FPFH (Fast Point Feature Histograms)\n",
    "FPFH [Rusu et al, 2008] is a histogram feature of relative angles and distances between neighbor points.\n",
    "\n",
    "This subsection use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from tutlibs.normal_estimation import normal_estimation\n",
    "from tutlibs.feature import PointFeatureHistograms as pfh\n",
    "from tutlibs.feature import pair_feature\n",
    "\n",
    "from tutlibs.io import Points as io\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PFH shape: (4093, 125)\n"
     ]
    }
   ],
   "source": [
    "xyz, _, _ = io.read('../data/bunny_pc.ply')\n",
    "normals = normal_estimation(xyz, 15)\n",
    "pfhs = pfh.compute(xyz, normals)\n",
    "print('PFH shape: {}'.format(pfhs.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    @staticmethod\n",
      "    def compute(\n",
      "        xyz: np.ndarray,\n",
      "        normals: np.ndarray,\n",
      "        radius=0.03,\n",
      "        div: int = 5,\n",
      "        normalization: bool = True,\n",
      "    ) -> np.ndarray:\n",
      "        \"\"\"Compute Point Feature Histograms.\n",
      "        Note: does not include the distance feature (reason -> https://pcl.readthedocs.io/projects/tutorials/en/latest/pfh_estimation.html#pfh-estimation)\n",
      "\n",
      "        Args:\n",
      "            xyz: xyz coords (N, 3)\n",
      "            normals: normals (N, 3)\n",
      "            radius: radius for nearest neighbor search\n",
      "            div: number of subdivisions of value range for each feature.\n",
      "            normalization: normalize each point histgram.\n",
      "\n",
      "        Return:\n",
      "            point feature histograms: (N, div**3)\n",
      "        \"\"\"\n",
      "        knn_idxs, _ = radius_nearest_neighbors(xyz, xyz, r=radius)\n",
      "\n",
      "        # define PFH list\n",
      "        num_pf = len(knn_idxs)  # num_pf = N = xyz.shape[0]\n",
      "        pfh_list = np.zeros((num_pf, div ** 3))\n",
      "\n",
      "        for i in range(num_pf):\n",
      "            # Get point set in radius (R=number of points in radius, R is different for each i.)\n",
      "            rnn_xyz = xyz[knn_idxs[i]]  # shape: (R, 3)\n",
      "            rnn_normal = normals[knn_idxs[i]]  # shape: (R, 3)\n",
      "\n",
      "            if len(rnn_xyz) >= 2:\n",
      "                pair_idxs = np.array(\n",
      "                    list(itertools.combinations(range(len(rnn_xyz)), 2))\n",
      "                )  # shape: (T, 2), T=Number of combinations\n",
      "                phi, alpha, theta, _ = pair_feature(\n",
      "                    rnn_xyz, rnn_normal, pair_idxs\n",
      "                )  # shape: (T), (T), (T), (T)\n",
      "\n",
      "                theta_bin_idx = fminmax(\n",
      "                    np.floor((div * (theta + np.pi)) / (2.0 * np.pi)), 0, div - 1\n",
      "                )\n",
      "                alpha_bin_idx = fminmax(\n",
      "                    np.floor(div * ((alpha + 1.0) * 0.5)), 0, div - 1\n",
      "                )\n",
      "                phi_bin_idx = fminmax(np.floor(div * ((phi + 1.0) * 0.5)), 0, div - 1)\n",
      "\n",
      "                histgram_idx = (\n",
      "                    phi_bin_idx * (div ** 2) + alpha_bin_idx * (div) + theta_bin_idx\n",
      "                ).astype(np.int32)\n",
      "                histgram = np.bincount(histgram_idx, minlength=div ** 3).astype(\n",
      "                    np.float32\n",
      "                )\n",
      "                if normalization:\n",
      "                    histgram /= (\n",
      "                        len(rnn_xyz) * (len(rnn_xyz) - 1) / 2\n",
      "                    )  # ex: np.sum(histgram) = 1\n",
      "            else:\n",
      "                histgram = np.zeros(div ** 3)\n",
      "\n",
      "            pfh_list[i] = histgram\n",
      "\n",
      "        return pfh_list\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(pfh.compute))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPF (Point Pair Feature)\n",
    "PFF [Drost et al, 2010] is features that have the relative distance and normal angle between 2 points.\n",
    "\n",
    "This subsection use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tutlibs.normal_estimation import normal_estimation\n",
    "from tutlibs.feature import PairPointFeature as ppf\n",
    "\n",
    "from tutlibs.io import Points as io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz, rgb, _ = io.read('../data/bunny_pc.ply')\n",
    "normals = normal_estimation(xyz)\n",
    "ppfs = ppf.compute(xyz, normals)\n",
    "print('PPF shape: {}'.format(ppfs.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "- [Rusu, R. B., N. Blodow, Z. C. Marton, and M. Beetz. 2008. “Aligning Point Cloud Views Using Persistent Feature Histograms.” In 2008 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE. https://doi.org/10.1109/iros.2008.4650967.](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.391.5915&rep=rep1&type=pdf)\n",
    "- [Rusu, Radu Bogdan, Nico Blodow, and Michael Beetz. 2009. “Fast Point Feature Histograms (FPFH) for 3D Registration.” In 2009 IEEE International Conference on Robotics and Automation, 3212–17.](https://www.cvl.iis.u-tokyo.ac.jp/class2016/2016w/papers/6.3DdataProcessing/Rusu_FPFH_ICRA2009.pdf)\n",
    "- [Drost, Bertram, Markus Ulrich, Nassir Navab, and Slobodan Ilic. 2010. “Model Globally, Match Locally: Efficient and Robust 3D Object Recognition.” In 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. IEEE. https://doi.org/10.1109/cvpr.2010.5540108.](http://campar.in.tum.de/pub/drost2010CVPR/drost2010CVPR.pdf)\n",
    "- [Rusu, R.B. Semantic 3D Object Maps for Everyday Manipulation in Human Living Environments. Künstl Intell 24, 345–348 (2010). https://doi.org/10.1007/s13218-010-0059-6](https://link.springer.com/article/10.1007/s13218-010-0059-6#citeas)\n",
    "- [Rusu, Radu Bogdan, Zoltan Csaba Marton, Nico Blodow, and Michael Beetz. 2008. “Learning Informative Point Classes for the Acquisition of Object Model Maps.” In 2008 10th International Conference on Control, Automation, Robotics and Vision. IEEE. https://doi.org/10.1109/icarcv.2008.4795593.](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.584.2647&rep=rep1&type=pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
